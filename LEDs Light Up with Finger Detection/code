# First, I'm importing the libraries I need:
# - `cv2` for working with the webcam and images
# - `serial` for talking to my Arduino
# - `numpy` for some math stuff I'll need later
import cv2
import serial
import numpy as np

# Now, I need to set up communication with my Arduino.
# I'm using COM3 here because that's where my Arduino is connected on my PC.
# If you're on Linux or Mac, the port will look different, like '/dev/ttyUSB0'.
arduino = serial.Serial('COM3', 9600)

# Next, I'm setting up my webcam. `0` means the default webcam.
# If you have multiple cameras, you might need to change this to `1` or another number.
cap = cv2.VideoCapture(0)

# I'm using a `while` loop to keep things running until I tell it to stop.
while True:
    # Read a frame from the webcam. `ret` tells me if it worked, and `frame` is the actual image.
    ret, frame = cap.read()

    # If the webcam didn't give me a frame, I just exit the loop.
    if not ret:
        break

    # Flip the image horizontally so it looks like a mirror.
    frame = cv2.flip(frame, 1)

    # I'm only interested in a small part of the image (where my hand will be),
    # so I define a region of interest (ROI) between (100,100) and (400,400).
    roi = frame[100:400, 100:400]

    # To make it easier to see where this ROI is, I draw a rectangle around it on the main frame.
    cv2.rectangle(frame, (100, 100), (400, 400), (255, 0, 0), 2)

    # Converting the ROI to grayscale so I can process it better.
    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)

    # Blurring the image to reduce noise (details I don't care about).
    blur = cv2.GaussianBlur(gray, (35, 35), 0)

    # Thresholding the image to make it black and white (binary).
    # I'm using `THRESH_BINARY_INV` to invert the colors because it makes detecting my hand easier.
    # `THRESH_OTSU` automatically figures out the best threshold value for me.
    _, thresh = cv2.threshold(blur, 127, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

    # Finding the outlines (contours) of shapes in the thresholded image.
    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

    # If I find any contours, I go ahead and process them.
    if contours:
        # The largest contour is probably my hand.
        max_contour = max(contours, key=cv2.contourArea)

        # Finding the convex hull of my hand (kind of like tracing around the outermost points).
        hull = cv2.convexHull(max_contour)

        # Now I'm finding "convexity defects," which are gaps between the hull and the contour.
        hull_indices = cv2.convexHull(max_contour, returnPoints=False)
        defects = cv2.convexityDefects(max_contour, hull_indices)

        # I'm going to count fingers. Starting at zero.
        finger_count = 0

        # If there are defects (like gaps between fingers), I process them.
        if defects is not None:
            for i in range(defects.shape[0]):
                # Each defect has a start, end, and a far point.
                start, end, far, _ = defects[i, 0]
                start_point = tuple(max_contour[start][0])
                end_point = tuple(max_contour[end][0])
                far_point = tuple(max_contour[far][0])

                # Calculating the distances and angles to figure out if it's a finger.
                a = np.linalg.norm(np.array(start_point) - np.array(far_point))
                b = np.linalg.norm(np.array(end_point) - np.array(far_point))
                c = np.linalg.norm(np.array(start_point) - np.array(end_point))
                angle = np.arccos((b**2 + c**2 - a**2) / (2 * b * c)) * 57  # Converting radians to degrees.

                # If the angle is less than 90Â°, it's a finger.
                if angle <= 90:
                    finger_count += 1

        # Sending the finger count to the Arduino to control the LEDs.
        # The Arduino expects bytes, so I send numbers as bytes like `b'0'`.
        if finger_count == 0:
            arduino.write(b'0')  # All LEDs off.
        elif finger_count == 1:
            arduino.write(b'1')  # Light 1 LED.
        elif finger_count == 2:
            arduino.write(b'2')  # Light 2 LEDs.
        elif finger_count >= 3:
            arduino.write(b'3')  # Light 3 LEDs.

        # Adding text to the video feed to show the number of fingers detected.
        cv2.putText(frame, f"Fingers: {finger_count}", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)

    # Showing the live video feed with the rectangle and finger count.
    cv2.imshow("Frame", frame)
    # Also showing the thresholded binary image to see how it looks.
    cv2.imshow("Threshold", thresh)

    # Waiting for a key press. If 'q' is pressed, the loop will break.
    key = cv2.waitKey(1) & 0xFF
    if key == ord('q'):
        break

# After the loop, I release the webcam and close all OpenCV windows.
cap.release()
cv2.destroyAllWindows()
